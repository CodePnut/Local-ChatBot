# ü¶ô Local Chatbot using LLaMA

Welcome to the **Local Chatbot using LLaMA** project! This project demonstrates how to create a simple conversational AI chatbot using the LLaMA model and the LangChain library.

## üìã Description

This project sets up a local chatbot that can answer questions based on the conversation history. It uses the `OllamaLLM` model from the `langchain_ollama` package and the `ChatPromptTemplate` from the `langchain_core` package to generate responses.

## üöÄ Features

- **Conversational AI**: The chatbot can maintain context and provide answers based on the conversation history.
- **Local Execution**: Runs entirely on your local machine without the need for external API calls.
- **Easy to Use**: Simple command-line interface to interact with the chatbot.

## üõ†Ô∏è Setup

1. **Clone the repository**:

   ```sh
   git clone https://github.com/yourusername/your-repository.git
   cd your-repository
   ```

2. **Create and activate a virtual environment**:

   ```sh
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install the required packages**:

   ```sh
   pip install langchain_ollama langchain_core
   ```

4. **Run the chatbot**:
   ```sh
   python main.py
   ```
